# Soft Robotics & AI — Evolution Gym Demo

This repo contains a short, live-demo–ready setup for **soft robotics + AI** using
[**Evolution Gym**](https://evolutiongym.github.io/) and **PPO** (Stable-Baselines3).
It accompanies our slides and talk on how **reinforcement learning** can discover gaits
for **voxel-based soft robots**.

## Repo Contents

```
.
├── train_evogym_better.py          # Improved PPO training (VecNormalize, larger net)
├── train_evogym_save.py            # Simple training that also saves robot.npz
├── play_evogym_saved_norm.py       # Playback using VecNormalize stats (recommended)
├── play_evogym.py                  # Legacy playback script (Gym API) – use Gymnasium versions instead
├── record_evogym_gif.py            # Render a short GIF/MP4 from a trained policy
├── robot.npz                       # Saved robot morphology (generated by training)
├── ppo_evogym_walker.zip           # Trained PPO policy (generated by training)
├── vecnormalize.pkl                # Normalization stats (generated by training)
├── evogym_demo.gif                 # Example animation (optional)
├── Soft_Robotics_AI_Presentation_EvoGym.pptx
├── Soft_Robotics_AI_Speech.pdf
├── Soft_Robotics_AI_Updated_Speech.pdf
├── requirements.txt
└── README.md
```

> Note: `robot.npz`, `ppo_evogym_walker.zip`, and `vecnormalize.pkl` are **artifacts** produced by training.
> You can delete and regenerate them at any time.

## Quickstart

### 1) Create an environment (Python 3.10 recommended)

Using **conda**:
```bash
conda create -n evogym python=3.10 -y
conda activate evogym
```

### 2) Install dependencies

```bash
pip install --upgrade pip setuptools wheel
pip install -r requirements.txt
```

### 3) Train (fast-to-good)

Recommended script (normalization + better defaults):

```bash
python train_evogym_better.py --timesteps 300000 --out ppo_evogym_walker --size 6
```

- **Shorter rehearsal run:** `--timesteps 150000`
- **Longer, stronger gait:** `--timesteps 500000`

This produces:
- `robot.npz` — the exact robot body used
- `ppo_evogym_walker.zip` — trained policy (the “brain”)
- `vecnormalize.pkl` — observation/reward normalization statistics

### 4) Replay (with normalization)

```bash
python play_evogym_saved_norm.py
```

This loads the **same robot** and the **VecNormalize** stats to reproduce training behavior faithfully.

### 5) Make a GIF / MP4 (for slides)

```bash
python record_evogym_gif.py --steps 500 --fps 30 --gif evogym_demo.gif --mp4 evogym_demo.mp4
```

## What “training” does (in one paragraph)

We place a voxel-based soft robot in an environment like `Walker-v0`. A neural-network **policy** outputs
actuator commands (expand/contract). The simulator returns a **reward** (e.g., forward distance). Using **PPO**
(reinforcement learning), the policy is updated to increase future reward. Over many steps, the robot discovers a **gait**.
The outputs (`ppo_evogym_walker.zip`, `robot.npz`) let you replay the learned behavior.

## Troubleshooting

- **Window doesn’t render (macOS):** `pip install pyglet` (already in requirements). Ensure scripts use `render_mode="human"` for live windows or `"rgb_array"` for offscreen capture.
- **Playback mismatch error (action dims):** You trained with a different robot. Use the saved `robot.npz` (already handled by `play_evogym_saved_norm.py`), or retrain and keep artifacts together.
- **Slow learning:** Increase `--timesteps` (300k→500k), reduce body size (`--size 5`), or lower LR to `1e-4`. You can also parallelize envs in `train_evogym_better.py` (2× `DummyVecEnv`).

## Create & Push a GitHub Repo

1. **On GitHub:** Create a new repo (e.g., `soft-robotics-ai-evogym`) — no need to initialize with README.
2. **In this folder:**
   ```bash
   git init
   git branch -M main
   echo "__pycache__/
*.pyc
*.pkl
*.zip
*.gif
*.mp4
.env
.venv
*egg-info/
.DS_Store
" > .gitignore
   git add .
   git commit -m "Soft Robotics & AI demo: Evolution Gym + PPO"
   ```
3. **Add remote & push (choose HTTPS or SSH):**
   ```bash
   # HTTPS (replace USER/REPO)
   git remote add origin https://github.com/USER/soft-robotics-ai-evogym.git
   git push -u origin main

   # or SSH
   git remote add origin git@github.com:USER/soft-robotics-ai-evogym.git
   git push -u origin main
   ```

> If any files exceed 100MB (unlikely here), use **Git LFS**:
> `git lfs install && git lfs track "*.zip" "*.mp4"`

## Acknowledgments

- **Evolution Gym** authors and maintainers
- **Stable-Baselines3** team
- Inspiration from bio-inspired soft robotics research communities

---

Happy experimenting! If you hit snags, open an issue or ping us.
